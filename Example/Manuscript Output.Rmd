---
title: "Overcoming the impacts of two-step batch effect correction on gene expression estimation and inference"
author: "Tenglong Li"
date: "12/29/2020"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    theme: "flatly"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE,error = FALSE,fig.align = 'center',fig.width = 15,fig.height = 8)
```

## Examples

* Example 1: Simulation study based on the *bladderbatch* dataset
* Example 2: *Towfic and others (2016)*
* Example 3: *Johnson and others (2007)*
* Example 4: *Progressors versus non-progressors in tuberculosis*

### Example 1: Simulation study based on the *bladderbatch* dataset

#### First, load all the required packages and create necessary wrappers
```{r load the packages}
defaultW <- getOption("warn") 
options(warn = -1) 
library(sva)
library(limma)
library(invgamma)
library(tidyverse)
library(BiocParallel)
library(SummarizedExperiment)
vrnorm <- Vectorize(rnorm,c('mean','sd'))
vinvrgamma <- Vectorize(rinvgamma,c('shape','rate'))
```

#### Second, load the simulation functions
```{r simulation functions}

#########################################################
## The no-reference-batch version of simbatch function ##
#########################################################

simbatch=function(sample,treated,intercept,mean,var,alpha,beta,res,eff){
  library(sva)
  library(invgamma)
  library(BiocParallel)
  library(Matrix)
  batch <- length(sample)
  size <- sum(sample)
  gene <- length(res)
  output <- mat.or.vec(gene,13)
  k <- cumsum(sample)
  x2 <- mat.or.vec(size,batch-1)
  x1 <- rep(c(0,1),times=c(sample[1]-treated[1],treated[1])) ## Treatment indicator
  for (i in 1:(batch-1)){
    x1 <- c(x1,rep(c(0,1),times=c(sample[i+1]-treated[i+1],treated[i+1])))
    x2[(k[i]+1):k[i+1],i] <- 1
  }
  x22 <- as.matrix(cbind(rep(c(1,0),times=c(sample[1],size-sample[1])),x2)) ## For simulation only
  x11 <- as.matrix(cbind(1,x1))
  xx <- as.matrix(cbind(x11,x2))
  x <- as.matrix(cbind(x11,x22))
  h1 <- x1%*%solve(t(x1)%*%x1)%*%t(x1)
  h12 <- x22%*%solve(t(x22)%*%(diag(size)-h1)%*%x22)%*%t(x22)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  batchind <- rep(1:batch,times=sample)
  mod <- model.matrix(~x1)
  mod0 <- model.matrix(~1,data=data.frame(x))
  varbatch <- t(vinvrgamma(gene,shape=alpha,rate=beta))[rep(1:batch,times=sample),]
  resid <- vrnorm(size,mean = 0, sd = res)
  meanbatch <- t(vrnorm(gene,mean,var^0.5))
  null <- mat.or.vec(batch,gene)
  y0 <- t(x%*%rbind(intercept,eff,null)+resid)
  y <- t(x%*%rbind(intercept,eff,meanbatch)+resid*varbatch)
  output[,1] <- eff
  output[,2] <- f.pvalue(y,mod,mod0) ## Raw Data T-Test
  mod1 <- model.matrix(~xx-1)
  mod10 <- model.matrix(~xx[,-2]-1)
  output[,3] <- f.pvalue(y,mod1,mod10) ## One step approach
  output[,4] <- f.pvalue(y0,mod,mod0) ## Benchmark approach, no batch effect
  eb <-ComBat(y,batch = batchind,mod = mod) 
  ## eb <- cbmod$adjdata
  output[,5] <- f.pvalue(eb,mod,mod0) ## ComBat without adjustment
  ## Try the correlation matrix formed by reduce 
  ## Choose delta as 10%
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  noise=sum(d)*0.1
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,6] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 5%
  d=eigen(m)$'values'
  noise=sum(d)*0.05
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,7] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 2%
  d=eigen(m)$'values'
  noise=sum(d)*0.02
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,8] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 1%
  d=eigen(m)$'values'
  noise=sum(d)*0.01
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,9] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.5%
  d=eigen(m)$'values'
  noise=sum(d)*0.005
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,10] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.1%
  d=eigen(m)$'values'
  noise=sum(d)*0.001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,11] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.01%
  d=eigen(m)$'values'
  noise=sum(d)*0.0001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,12] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.001%
  d=eigen(m)$'values'
  noise=sum(d)*0.00001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,13] <- f.pvalue(reb,mod4,mod40)
  colnames(output) <- c('TEff','T','1step','Bench','EB',paste0('EB',c(0.1,0.05,0.02,0.01,0.005,0.001,0.0001,0.00001)))
  ## result <- apply(output,2,function(x) length(x[x<0.05])/length(x))
  return(output)
}

simbatch <- compiler::cmpfun(simbatch)


##################################################
## Simple simulation for mean batch effect only ##
##################################################

simbatch1=function(sample,treated,intercept,mean,var,res,eff){
  library(sva)
  library(BiocParallel)
  library(Matrix)
  batch <- length(sample)
  size <- sum(sample)
  gene <- length(res)
  output <- mat.or.vec(gene,13)
  k <- cumsum(sample)
  x2 <- mat.or.vec(size,batch-1)
  x1 <- rep(c(0,1),times=c(sample[1]-treated[1],treated[1])) ## Treatment indicator
  for (i in 1:(batch-1)){
    x1 <- c(x1,rep(c(0,1),times=c(sample[i+1]-treated[i+1],treated[i+1])))
    x2[(k[i]+1):k[i+1],i] <- 1
  }
  x22 <- as.matrix(cbind(rep(c(1,0),times=c(sample[1],size-sample[1])),x2)) ## For simulation only
  x11 <- as.matrix(cbind(1,x1))
  xx <- as.matrix(cbind(x11,x2))
  x <- as.matrix(cbind(x11,x22))
  h1 <- x1%*%solve(t(x1)%*%x1)%*%t(x1)
  h12 <- x22%*%solve(t(x22)%*%(diag(size)-h1)%*%x22)%*%t(x22)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  batchind <- rep(1:batch,times=sample)
  mod <- model.matrix(~x1)
  mod0 <- model.matrix(~1,data=data.frame(x))
  resid <- vrnorm(size,mean = 0, sd = res)
  meanbatch <- t(vrnorm(gene,mean,var^0.5))
  null <- mat.or.vec(batch,gene)
  y0 <- t(x%*%rbind(intercept,eff,null)+resid)
  y <- t(x%*%rbind(intercept,eff,meanbatch)+resid)
  output[,1] <- eff
  output[,2] <- f.pvalue(y,mod,mod0) ## Raw Data T-Test
  mod1 <- model.matrix(~xx-1)
  mod10 <- model.matrix(~xx[,-2]-1)
  output[,3] <- f.pvalue(y,mod1,mod10) ## One step approach
  output[,4] <- f.pvalue(y0,mod,mod0) ## Benchmark approach, no batch effect
  eb <-ComBat(y,batch = batchind,mod = mod,mean.only = TRUE) 
  ## eb <- cbmod$adjdata
  output[,5] <- f.pvalue(eb,mod,mod0) ## ComBat without adjustment
  ## Try the correlation matrix formed by reduce 
  ## Choose delta as 10%
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  noise=sum(d)*0.1
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,6] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 5%
  d=eigen(m)$'values'
  noise=sum(d)*0.05
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,7] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 2%
  d=eigen(m)$'values'
  noise=sum(d)*0.02
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,8] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 1%
  d=eigen(m)$'values'
  noise=sum(d)*0.01
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,9] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.5%
  d=eigen(m)$'values'
  noise=sum(d)*0.005
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,10] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.1%
  d=eigen(m)$'values'
  noise=sum(d)*0.001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,11] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.01%
  d=eigen(m)$'values'
  noise=sum(d)*0.0001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,12] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.001%
  d=eigen(m)$'values'
  noise=sum(d)*0.00001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,13] <- f.pvalue(reb,mod4,mod40)
  colnames(output) <- c('TEff','T','1step','Bench','EB',paste0('EB',c(0.1,0.05,0.02,0.01,0.005,0.001,0.0001,0.00001)))
  ## result <- apply(output,2,function(x) length(x[x<0.05])/length(x))
  return(output)
}

simbatch1 <- compiler::cmpfun(simbatch1)

##########################################################
## The simple simulation for variance batch effect only ##
##########################################################

simbatch2=function(sample,treated,intercept,alpha,beta,res,eff){
  library(sva)
  library(invgamma)
  library(BiocParallel)
  library(Matrix)
  batch <- length(sample)
  size <- sum(sample)
  gene <- length(res)
  output <- mat.or.vec(gene,13)
  k <- cumsum(sample)
  x2 <- mat.or.vec(size,batch-1)
  x1 <- rep(c(0,1),times=c(sample[1]-treated[1],treated[1])) ## Treatment indicator
  for (i in 1:(batch-1)){
    x1 <- c(x1,rep(c(0,1),times=c(sample[i+1]-treated[i+1],treated[i+1])))
    x2[(k[i]+1):k[i+1],i] <- 1
  }
  x22 <- as.matrix(cbind(rep(c(1,0),times=c(sample[1],size-sample[1])),x2)) ## For simulation only
  x11 <- as.matrix(cbind(1,x1))
  xx <- as.matrix(cbind(x11,x2))
  x <- as.matrix(cbind(x11,x22))
  h1 <- x1%*%solve(t(x1)%*%x1)%*%t(x1)
  h12 <- x22%*%solve(t(x22)%*%(diag(size)-h1)%*%x22)%*%t(x22)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  batchind <- rep(1:batch,times=sample)
  mod <- model.matrix(~x1)
  mod0 <- model.matrix(~1,data=data.frame(x))
  varbatch <- t(vinvrgamma(gene,shape=alpha,rate=beta))[rep(1:batch,times=sample),]
  resid <- vrnorm(size,mean = 0, sd = res)
  null <- mat.or.vec(batch,gene)
  y0 <- t(x%*%rbind(intercept,eff,null)+resid)
  y <- t(x%*%rbind(intercept,eff,null)+resid*varbatch)
  output[,1] <- eff
  output[,2] <- f.pvalue(y,mod,mod0) ## Raw Data T-Test
  mod1 <- model.matrix(~xx-1)
  mod10 <- model.matrix(~xx[,-2]-1)
  output[,3] <- f.pvalue(y,mod1,mod10) ## One step approach
  output[,4] <- f.pvalue(y0,mod,mod0) ## Benchmark approach, no batch effect
  eb <- ComBat(y,batch = batchind,mod = mod)
  ## eb <- cbmod$adjdata
  output[,5] <- f.pvalue(eb,mod,mod0) ## ComBat without adjustment
  ## Try the correlation matrix formed by reduce 
  ## Choose delta as 10%
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  noise=sum(d)*0.1
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,6] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 5%
  d=eigen(m)$'values'
  noise=sum(d)*0.05
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,7] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 2%
  d=eigen(m)$'values'
  noise=sum(d)*0.02
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,8] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 1%
  d=eigen(m)$'values'
  noise=sum(d)*0.01
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,9] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.5%
  d=eigen(m)$'values'
  noise=sum(d)*0.005
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,10] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.1%
  d=eigen(m)$'values'
  noise=sum(d)*0.001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,11] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.01%
  d=eigen(m)$'values'
  noise=sum(d)*0.0001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,12] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.001%
  d=eigen(m)$'values'
  noise=sum(d)*0.00001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,13] <- f.pvalue(reb,mod4,mod40)
  colnames(output) <- c('TEff','T','1step','Bench','EB',paste0('EB',c(0.1,0.05,0.02,0.01,0.005,0.001,0.0001,0.00001)))
  ## result <- apply(output,2,function(x) length(x[x<0.05])/length(x))
  return(output)
}

simbatch2 <- compiler::cmpfun(simbatch2)
```


#### Third, generate simulation results

```{r simulation results}
set.seed(123)
## Simulation design: 3*3
unbalanced <- vector("list",9)
names(unbalanced) <- c("No mean batch effect & No variance batch effect","Small mean batch effect & No variance batch effect",
                       "Large mean batch effect & No variance batch effect","No mean batch effect & Small variance batch effect",
                       "No mean batch effect & Large variance batch effect","Small mean batch effect & Small variance batch effect",
                       "Large mean batch effect & Small variance batch effect","Small mean batch effect & Large variance batch effect",
                       "Large mean batch effect & Large variance batch effect")
## For unbalanced design
## Just mean batch effect only
## No mean batch effect & No variance batch effect
out <- simbatch1(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=rep(0,5),var=rep(0,5),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[1]] <- out
## Small mean batch effect & No variance batch effect
out <- simbatch1(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[2]] <- out
## Large mean batch effect & No variance batch effect
out <- simbatch1(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[3]] <- out
## Just variance batch effect only
## No mean batch effect & Small variance batch effect 
out <- simbatch2(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[4]] <- out
## No mean batch effect & Large variance batch effect
out <- simbatch2(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[5]] <- out
## Have both mean batch effect and variance batch effect
## Small mean batch effect & Small variance batch effect
out <- simbatch(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[6]] <- out
## Large mean batch effect & Small variance batch effect
out <- simbatch(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[7]] <- out
## Small mean batch effect & Large variance batch effect
out <- simbatch(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[8]] <- out
## Large mean batch effect & Large variance batch effect 
out <- simbatch(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
unbalanced[[9]] <- out
## For balanced design
set.seed(123)
balanced <- vector("list",9)
names(balanced) <- c("No mean batch effect & No variance batch effect","Small mean batch effect & No variance batch effect",
                       "Large mean batch effect & No variance batch effect","No mean batch effect & Small variance batch effect",
                       "No mean batch effect & Large variance batch effect","Small mean batch effect & Small variance batch effect",
                       "Large mean batch effect & Small variance batch effect","Small mean batch effect & Large variance batch effect",
                       "Large mean batch effect & Large variance batch effect")
## For balanced design
## Just mean batch effect only
## No mean batch effect & No variance batch effect
out <- simbatch1(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=rep(0,5),var=rep(0,5),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[1]] <- out
## Small mean batch effect & No variance batch effect
out <- simbatch1(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[2]] <- out
## Large mean batch effect & No variance batch effect
out <- simbatch1(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[3]] <- out
## Just variance batch effect only
## No mean batch effect & Small variance batch effect 
out <- simbatch2(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[4]] <- out
## No mean batch effect & Large variance batch effect
out <- simbatch2(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[5]] <- out
## Have both mean batch effect and variance batch effect
## Small mean batch effect & Small variance batch effect
out <- simbatch(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[6]] <- out
## Large mean batch effect & Small variance batch effect
out <- simbatch(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[7]] <- out
## Small mean batch effect & Large variance batch effect
out <- simbatch(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[8]] <- out
## Large mean batch effect & Large variance batch effect 
out <- simbatch(c(12,18,4,6,20),c(6,9,2,3,10),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.4,1.5,-1.5,-1,-0.8),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(100,120,100,60,40),beta=c(100,40,60,100,120),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
balanced[[9]] <- out
```

Create results in table 2 and 3:
```{r create tables}
## Postprocessing
## Process the result based on p values
processp <- function(out){
  out <- data.frame(out)
  result <- matrix(unlist(by(out[,-1],out$TEff,function(x) apply(x,2,function(x) length(x[x<0.05])))),nrow = 5,byrow = TRUE)
  ## Report FPR and TPR based on p values
  ## Report FPR
  output <- mat.or.vec(2,12)
  rownames(output) <- c('FPR','TPR')
  colnames(output) <- colnames(out)[-1]
  output[1,] <- apply(result,2,function(x) round(x[3]/18000,digits = 3))
  ## Report TPR
  output[2,] <- apply(result,2,function(x) round(sum(x[-3])/2000,digits = 3))
  return(output)
}
## Process the result based on q values
processq <- function(out){
  output <- mat.or.vec(2,12)
  rownames(output) <- c('FDR','TPR')
  colnames(output) <- colnames(out)[-1]
  out1 <- apply(out[,-1],2,function(x) p.adjust(x,method = "BH"))
  out1 <- cbind(out[,1],out1)
  out1 <- data.frame(out1)
  result <- matrix(unlist(by(out1[,-1],out1[,1],function(x) apply(x,2,function(x) length(x[x<0.05])))),nrow = 5,byrow = TRUE)
  ## Report FDR
  output[1,] <- apply(result,2,function(x) x[3]/sum(x))
  ## Report TPR
  output[2,] <- apply(result,2,function(x) sum(x[-3])/2000)
  return(output)
}
u <- lapply(unbalanced,processp)
b <- lapply(balanced,processp)
```

Table 2: 
```{r table 2}
print(u)
```

Table 3:
```{r table 3}
print(b)
```


#### Create figure 1
```{r,fig.keep="none"}
## Generate Line-Histogram Plot for small mean and variance batch effect
out <- simbatch(c(11,18,4,5,19),c(11,14,0,0,15),intercept=3+rgamma(20000,4.5,1.5),mean=c(-0.04,0.15,-0.15,-0.1,-0.08),var=c(0.15,0.35,0.82,0.46,0.12),alpha=c(60,100,56,30,100),beta=c(60,100,50,30,100),res=rgamma(20000,4,10),eff=c(rep(0,18000),rep(c(-2,-1,1,2),each=500)))
out <- data.frame(out)
x=invisible(hist(out$EB))
y=invisible(hist(out$Bench))
z=invisible(hist(out$EB0.01))
```

```{r figure 1}
## QQ Plot with reference line at Benchmark
par(mfrow=c(1,3))
qqplot(out$EB,out$Bench,xlab = "ComBat", ylab = "Benchmark",cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(a) QQ plot of ComBat versus Benchmark')
abline(a=0,b=1,lty=2,lwd=2)
qqplot(out$EB0.01,out$Bench,xlab="ComBat+Cor",ylab='Benchmark',cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(b) QQ plot of ComBat+Cor versus Benchmark')
abline(a=0,b=1,lty=2,lwd=2)
plot(x$breaks[-length(x$breaks)],x$counts,type='l',ylab='Frequency',xlab='p-value',lwd=2,cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(c) Distributions of p-values for the three approaches')
lines(y$breaks[-length(y$breaks)],y$counts,lty=2,lwd=2)
lines(z$breaks[-length(z$breaks)],z$counts,lty=3,lwd=2)
legend('topright',legend = c('Benchmark','ComBat','ComBat+Cor'),lty=c(2,1,3),lwd=c(2,2,2),cex = 1.5,xjust = 0.5,yjust = 0.5)
par(mfrow=c(1,1))
```


#### Create figure 2 

```{r figure 2}
tpr_u <- apply(do.call("rbind",lapply(u,function(x) x[2,5:12])),2,mean)
fpr_u <- apply(do.call("rbind",lapply(u,function(x) x[1,5:12])),2,mean)
tpr_b <- apply(do.call("rbind",lapply(b,function(x) x[2,5:12])),2,mean)
fpr_b <- apply(do.call("rbind",lapply(b,function(x) x[1,5:12])),2,mean)
delta <-factor(c('10%','5%','2%','1%','0.5%','0.1%','0.01%','0.001%'),levels=c('10%','5%','2%','1%','0.5%','0.1%','0.01%','0.001%'))
dat <- cbind.data.frame(delta,unbalanced=tpr_u,balanced=tpr_b)
dat1 <- cbind.data.frame(delta,unbalanced=fpr_u,balanced=fpr_b)
dat <- dat%>%gather(key = 'design',value = 'value',-delta)
ggplot(data=dat,aes(x=delta,y=value,group=design))+geom_point(aes(shape=design))+geom_line(aes(linetype=design))+labs(x=expression(zeta),y='TPR')+theme_grey(base_size = 15)
```

#### Create figure 3

```{r figure 3}
dat1 <- dat1%>%gather(key = 'design',value = 'value',-delta)
ggplot(data=dat1,aes(x=delta,y=value,group=design))+geom_point(aes(shape=design))+geom_line(aes(linetype=design))+labs(x=expression(zeta),y='FPR')+theme_grey(base_size = 15)
```


### Example 2: *Towfic and others (2016)*

#### First, load the data
```{r load towfic}
# Downloads the non-normalized data from GSE40566
# Using the covariate annotation from GSE61901
loadtowfic = function(downloaddata=TRUE)
{
  geoaccession="GSE40566"
  rawfn = "http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE40566&format=file&file=GSE40566%5Fnon%5Fnormalized%2Etxt%2Egz"	
  
  #createsampleannotation() # ad.hoc function to create sampleannotation.txt based on GSE61901 and GSE40566
  sampleannotation = read.table("sampleannotation.txt", sep="\t",
                                header=TRUE, stringsAsFactors=FALSE)
  
  if(downloaddata)
  {
    temp = tempfile()    
    download.file(url=rawfn, destfile=temp, mode = "wb")
    datamatrix_raw = read.table(temp, sep="\t", header=TRUE, 
                                stringsAsFactors=FALSE, skip=0, strip.white=TRUE, fill=TRUE)
    unlink(temp)
  }else{
    datamatrix_raw = read.table(paste("not_in_github/",geoaccession,"_non-normalized.txt", sep=""), sep="\t", header=TRUE, 
                                stringsAsFactors=FALSE, skip=0, strip.white=TRUE, fill=TRUE)
  }
  
  rownames(datamatrix_raw) =  datamatrix_raw[,1]
  datamatrix_raw = datamatrix_raw[,-1]
  datamatrix_raw = as.matrix(datamatrix_raw)
  
  sampleannotation = sampleannotation[ match(sampleannotation$title, colnames(datamatrix_raw) ) , ]
  return(list(sampleannotation=sampleannotation, data=datamatrix_raw))
}	

# ad hoc function to fetch the covariate labels which are described in GSE61901 but not in GSE40566
# GSE40566 has a "relation" tag that connects to the sample in GSE61901 which has covaraite label.
# I dont know a method of getting the sample annotation from GEO whitout downloading the whole matrix (including the GPL).
createsampleannotation = function()
{
  require("GEOquery")
  GSE61901eset=getGEO("GSE61901")[[1]]
  GSE40566eset=getGEO("GSE40566")[[1]]
  
  #t(pData(GSE61901eset)[1,])
  GSE61901sa = pData(GSE61901eset)[, c("characteristics_ch1", "characteristics_ch1.3", "characteristics_ch1.2")]
  names(GSE61901sa) = c("batch", "covariate", "array_strip_address")
  GSE61901sa[,1]=gsub("batch: ", "", GSE61901sa[,1] )
  GSE61901sa[,2]=gsub("batchcovar: ", "", GSE61901sa[,2] )
  GSE61901sa[,3]=gsub("array_address: ", "", GSE61901sa[,3] )
  GSE61901sa[,"array_hyb_address"]=gsub("_[12]", "", GSE61901sa[,3] )
  # some renaming for conveniance
  
  GSE61901sa$covariate = make.names(GSE61901sa$covariate)
  GSE61901sa$covariate[GSE61901sa$covariate=="GA.DP"] = "DP"
  GSE61901sa$covariate[GSE61901sa$covariate=="GA.Q"] = "N"
  GSE61901sa$covariate[GSE61901sa$covariate=="Medium"] = "M"
  GSE61901sa$covariate[GSE61901sa$covariate=="GA.RS"] = "RS"
  
  #t(pData(GSE40566eset)[1,])
  GSE40566sa  = pData(GSE40566eset)[, c("title", "relation")]
  GSE40566sa$title = make.names(GSE40566sa$title)
  GSE40566sa[,"relation"]=gsub("Reanalyzed by: ", "", GSE40566sa[,"relation"] )
  GSE40566sa = cbind(GSE40566sa, GSE61901sa[GSE40566sa$relation,])
  write.table(GSE40566sa, file="sampleannotation.txt", sep="\t", col.names=NA, quote=FALSE)
}

ret = loadtowfic()
sampleannotation = ret[["sampleannotation"]]
rawdata = ret[["data"]]
library(sva)
library(limma)

qnormdata = normalizeBetweenArrays(rawdata, method="quantile") 


########################################################################
## Start here to read the data instead of download & process the data ##
########################################################################

adj_pval <- function(data,batchind,treat,noise){
  num_batch <- max(batchind)
  size <- length(batchind)
  batch <- mat.or.vec(size,num_batch)
  for (i in 1:num_batch){
    batch[,i] <- ifelse(batchind==i,1,0)
  }
  h1 <- treat%*%solve(t(treat)%*%treat)%*%t(treat)
  h12 <- batch%*%solve(t(batch)%*%(diag(size)-h1)%*%batch)%*%t(batch)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  n=sum(d)*noise
  d=ifelse(d<0.0001,n,d)
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  x11 <- as.matrix(cbind(1,treat))
  rex <- s%*%x11
  reb <- t(s%*%t(data))
  mod <- model.matrix(~rex-1)
  mod0 <- model.matrix(~rex[,1]-1)
  adj_p <- f.pvalue(reb,mod,mod0)
  return(adj_p)
}

adj_pval <- compiler::cmpfun(adj_pval)
```

#### Second, real data analysis

```{r towfic data analysis}
# combat adjust
library(sva)
combatdata <- as.matrix(ComBat(dat=qnormdata,
                             batch=sampleannotation$batch,
                             mod=model.matrix(~as.factor(sampleannotation$covariate))))

## Compare DP vs N 
select <- which(sampleannotation$covariate=='DP'|sampleannotation$covariate=='N')
ebdata <- combatdata[,select]
sample1 <- sampleannotation[select,]
t <- ifelse(sample1$covariate=='DP',1,0)
b <- factor(sample1$batch,labels = 1:17)
b <- as.numeric(b)
mod <- model.matrix(~t)
mod0 <- model.matrix(~1,data = sample1)
p1 <- as.numeric(f.pvalue(ebdata,mod,mod0))
p2 <- as.numeric(adj_pval(ebdata,b,t,0.01))
result <- data.frame(cbind(p1,p2))
p_diff <- length(which(result$p1<0.05&result$p2>0.05))
combat_sig_p <- length(which(result$p1<0.05))
combat_cor_sig_p <- length(which(result$p2<0.05))
result1=apply(result,2,function(x) p.adjust(x,method = "BH"))
result1 <- data.frame(result1)
q_diff <- length(which(result1$p1<0.05&result1$p2>0.05))
combat_sig_q <- length(which(result1$p1<0.05))
combat_cor_sig_q <- length(which(result1$p2<0.05))
```

Results based on p-values
```{r towfic p-values}
p_diff
combat_sig_p
combat_cor_sig_p
```

Results based on q-values
```{r towfic q-values}
q_diff
combat_sig_q
combat_cor_sig_q
```

#### Third, benchmarking by simulation and create figure 4 (a)

```{r towfic simulation,fig.keep='none'}
## Try to do simulation based on this data

#########################################################
## The no-reference-batch version of simbatch function ##
#########################################################

simbatch=function(sample,treated,intercept,mean,var,alpha,beta,res,eff){
  library(sva)
  library(invgamma)
  library(BiocParallel)
  library(Matrix)
  batch <- length(sample)
  size <- sum(sample)
  gene <- length(res)
  output <- mat.or.vec(gene,11)
  k <- cumsum(sample)
  x2 <- mat.or.vec(size,batch-1)
  x1 <- rep(c(0,1),times=c(sample[1]-treated[1],treated[1])) ## Treatment indicator
  for (i in 1:(batch-1)){
    x1 <- c(x1,rep(c(0,1),times=c(sample[i+1]-treated[i+1],treated[i+1])))
    x2[(k[i]+1):k[i+1],i] <- 1
  }
  x22 <- as.matrix(cbind(rep(c(1,0),times=c(sample[1],size-sample[1])),x2)) ## For simulation only
  x11 <- as.matrix(cbind(1,x1))
  xx <- as.matrix(cbind(x11,x2))
  x <- as.matrix(cbind(x11,x22))
  h1 <- x1%*%solve(t(x1)%*%x1)%*%t(x1)
  h12 <- x22%*%solve(t(x22)%*%(diag(size)-h1)%*%x22)%*%t(x22)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  batchind <- rep(1:batch,times=sample)
  mod <- model.matrix(~x1)
  mod0 <- model.matrix(~1,data=data.frame(x))
  varbatch <- t(vinvrgamma(gene,shape=alpha,rate=beta))[rep(1:batch,times=sample),]
  resid <- vrnorm(size,mean = 0, sd = res)
  meanbatch <- t(vrnorm(gene,mean,var^0.5))
  null <- mat.or.vec(batch,gene)
  y0 <- t(x%*%rbind(intercept,eff,null)+resid)
  y <- t(x%*%rbind(intercept,eff,meanbatch)+resid*varbatch)
  cy <- t(reduce%*%t(y))
  output[,1] <- eff
  output[,2] <- f.pvalue(y,mod,mod0) ## Raw Data T-Test
  mod1 <- model.matrix(~xx-1)
  mod10 <- model.matrix(~xx[,-2]-1)
  output[,3] <- f.pvalue(y,mod1,mod10) ## One step approach
  output[,4] <- f.pvalue(y0,mod,mod0) ## Benchmark approach, no batch effect
  output[,5] <- f.pvalue(cy,mod,mod0) ## Two step approach without adjustment
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  d=ifelse(d<0.01,0.01,d) ## t is the threshold, typically chosen as 0.01
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  ecy <- t(s%*%t(cy))
  rx11 <- s%*%x11
  mod2 <- model.matrix(~rx11-1)
  mod20 <- model.matrix(~rx11[,1]-1)
  output[,6] <- f.pvalue(ecy,mod2,mod20) ## Two step approach with adjustment 
  eb <-ComBat(y,batch = batchind,mod = mod) ## Power would be reduced if choose a reference batch
  output[,7] <- f.pvalue(eb,mod,mod0) ## ComBat without adjustment
  ## Try the correlation matrix formed by reduce 
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  noise=sum(d)*0.1
  d=ifelse(d<0.0001,noise,d) ## t is the threshold, typically chosen as 0.1
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,8] <- f.pvalue(reb,mod4,mod40)
  ## Try the correlation matrix formed by reduce
  d=eigen(m)$'values'
  noise=sum(d)*0.01
  d=ifelse(d<0.0001,noise,d) ## t is the threshold, typically chosen as 0.01
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,9] <- f.pvalue(reb,mod4,mod40)
  ## Try the correlation matrix formed by reduce
  d=eigen(m)$'values'
  noise=sum(d)*0.001
  d=ifelse(d<0.0001,noise,d) ## t is the threshold, typically chosen as 0.001
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,10] <- f.pvalue(reb,mod4,mod40)
  ## Try the correlation matrix formed by reduce
  d=eigen(m)$'values'
  noise=sum(d)*0.00001
  d=ifelse(d<0.0001,noise,d) ## t is the threshold, typically chosen as 0.1
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,11] <- f.pvalue(reb,mod4,mod40)
  colnames(output) <- c('TEff','T','1step','Bench','2step','2step_A','EB','EB_A1','EB_A2','EB_A3','EB_A4')
  ## result <- apply(output,2,function(x) length(x[x<0.05])/length(x))
  return(output)
}

simbatch <- compiler::cmpfun(simbatch)

qnormdata1 <- qnormdata[,select]
eb <- ComBat(dat=qnormdata1, batch=sample1$batch, mod=model.matrix(~as.factor(sample1$covariate)))
batch <- as.numeric(table(b))
control <- numeric(17)
control[c(2,3,6,7,8,9,11,12)] <- c(2,1,1,1,1,1,2,2)
treat <- batch-control
out <- simbatch(batch,treat,intercept =5+rgamma(46547,3,1.8),mean = rep(0,17),var = c(4,16,9,16,9,4,8,10,12,18,16,14,20,20,15,18,25),alpha = rep(150,17),beta = rep(150,17),res = rgamma(46547,1,12),eff = c(rep(0,46447),rep(c(-1,1),each=50)))
out <- data.frame(out)
## Histogram lines plot based on simulation
x=invisible(hist(out$EB))
y=invisible(hist(out$Bench))
z=invisible(hist(out$EB_A2))
```

```{r figure 4a}
plot(x$breaks[-length(x$breaks)],x$counts,type='l',ylab='Frequency',xlab='p-value',lwd=2,cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(a) Example 2')
lines(y$breaks[-length(y$breaks)],y$counts,lty=2,lwd=2)
lines(z$breaks[-length(z$breaks)],z$counts,lty=3,lwd=2)
legend('topright',legend = c('Benchmark','ComBat','ComBat+Cor'),lty=c(2,1,3),lwd=c(2,2,2),cex = 1.5,xjust = 0.5,yjust = 0.5)
```

### Example 3: *Johnson and others (2007)*

#### First, load the data
```{r load johnson}
loadjohnsondata = function()
{  
  datamatrix = as.matrix(read.table("dataExample2.txt", sep="\t", header=TRUE))
  sampleannotation = read.table("sampleInfoExample2.txt", 
                                sep="\t", header=TRUE, stringsAsFactors=FALSE)
  rownames(sampleannotation)=sampleannotation$ArrayName
  sampleannotation$Batch=factor(as.character(sampleannotation$Batch)) 
  datamatrix=datamatrix[,sampleannotation$Type!="WT"]
  sampleannotation=sampleannotation[sampleannotation$Type!="WT",]
  sampleannotation$Type=factor(sampleannotation$Type)
  
  log2data = datamatrix
  # flooring to 1
  log2data[log2data<1]=1
  # take out data with to much low/missing values.
  negativeprobesfilter =( rowSums(log2data>1) >= (0.9*ncol(log2data)) )
  log2data = log2data[negativeprobesfilter,]
  # quantilenormalize
  log2data=normalizeBetweenArrays(log2(log2data), method="quantile")
  
  return(list(sampleannotation=sampleannotation, rawdata=datamatrix, normdata=log2data))
}
tmp = loadjohnsondata()
sampleannotation = tmp[["sampleannotation"]]
normdata = tmp[["normdata"]]
```

#### Second, real data analysis
```{r johnson data analysis}
combatdata = as.matrix(ComBat(
  dat=normdata, 
  batch=sampleannotation$Batch, 
  mod=model.matrix(~as.factor(sampleannotation$"Type"))))
t <- ifelse(sampleannotation$Type=='R',1,0)
b <- as.numeric(sampleannotation$Batch)
mod <- model.matrix(~t)
mod0 <- model.matrix(~1,data = sampleannotation)
p1 <- as.numeric(f.pvalue(combatdata,mod,mod0))
p2 <- as.numeric(adj_pval(combatdata,b,t,0.01))
result <- data.frame(cbind(p1,p2))
p_diff <- length(which(result$p1<0.05&result$p2>0.05))
combat_sig_p <- length(which(result$p1<0.05))
combat_cor_sig_p <- length(which(result$p2<0.05))
result1=apply(result,2,function(x) p.adjust(x,method = "BH"))
result1 <- data.frame(result1)
q_diff <- length(which(result1$p1<0.05&result1$p2>0.05))
combat_sig_q <- length(which(result1$p1<0.05))
combat_cor_sig_q <- length(which(result1$p2<0.05))
```

Results based on p-values
```{r johnson p-values}
p_diff
combat_sig_p
combat_cor_sig_p
```

Results based on q-values
```{r johnson q-values}
q_diff
combat_sig_q
combat_cor_sig_q
```

#### Third, benchmarking by simulation and create figure 4 (b)
```{r johnson simulation,fig.keep='none'}
out1 <- simbatch(c(8,7,15),c(6,3,9),intercept = rgamma(52275,12,1.8),mean = rep(0,3),var = c(0.5,0.3,0.15),alpha = rep(100,3),beta = rep(100,3),res = rgamma(52275,0.4,2),eff = c(rep(0,48275),rep(c(-2,-1,1,2),each=1000)))
out1 <- data.frame(out1)
x1=invisible(hist(out1$EB))
y1=invisible(hist(out1$Bench))
z1=invisible(hist(out1$EB_A2))
```

```{r figure 4b}
plot(x1$breaks[-length(x1$breaks)],x1$counts,type='l',ylab='Frequency',xlab='p-value',lwd=2,cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(b) Example 3')
lines(y1$breaks[-length(y1$breaks)],y1$counts,lty=2,lwd=2)
lines(z1$breaks[-length(z1$breaks)],z1$counts,lty=3,lwd=2)
legend('topright',legend = c('Benchmark','ComBat','ComBat+Cor'),lty=c(2,1,3),lwd=c(2,2,2),cex = 1.5,xjust = 0.5,yjust = 0.5)
```

### Example 4: *Progressors versus non-progressors in tuberculosis*

#### First, load the data and data analysis
```{r tb data analysis}
x3 <- readRDS("tbsample.rds")
x4 <- readRDS("tbdata.rds")
b <- as.numeric(factor(x3$SequencingBatch,labels = 1:3))
t <- ifelse(x3$Label=='Progressor',1,0)
mod <- model.matrix(~t)
eb <- ComBat(x4,batch = b,mod = mod)
mod0 <- model.matrix(~1,data=x3)
p1 <- as.numeric(f.pvalue(eb,mod,mod0))
p2 <- as.numeric(adj_pval(eb,b,t,0.001))
result <- data.frame(cbind(p1,p2))
p_diff <- length(which(result$p1<0.05&result$p2>0.05))
combat_sig_p <- length(which(result$p1<0.05))
combat_cor_sig_p <- length(which(result$p2<0.05))
## q-values for probe
result1 <- apply(result,2,function(x) p.adjust(x,method = "BH"))
result1 <- data.frame(result1)
colnames(result1) <- c('q1','q2')
q_diff <- length(which(result1$q1<0.05&result1$q2>0.05))
combat_sig_q <- length(which(result1$q1<0.05))
combat_cor_sig_q <-length(which(result1$q2<0.05))
```

Results based on p-values
```{r tb p-values}
p_diff
combat_sig_p
combat_cor_sig_p
```

Results based on q-values
```{r tb q-values}
q_diff
combat_sig_q
combat_cor_sig_q
```

#### Second, benchmarking by simulation and create figure 4 (c)
```{r tb simulation,fig.keep='none'}

#########################################################
## The no-reference-batch version of simbatch function ##
#########################################################

simbatch=function(sample,treated,intercept,mean,var,alpha,beta,res,eff){
  library(sva)
  library(invgamma)
  library(BiocParallel)
  library(Matrix)
  batch <- length(sample)
  size <- sum(sample)
  gene <- length(res)
  output <- mat.or.vec(gene,15)
  k <- cumsum(sample)
  x2 <- mat.or.vec(size,batch-1)
  x1 <- rep(c(0,1),times=c(sample[1]-treated[1],treated[1])) ## Treatment indicator
  for (i in 1:(batch-1)){
    x1 <- c(x1,rep(c(0,1),times=c(sample[i+1]-treated[i+1],treated[i+1])))
    x2[(k[i]+1):k[i+1],i] <- 1
  }
  x22 <- as.matrix(cbind(rep(c(1,0),times=c(sample[1],size-sample[1])),x2)) ## For simulation only
  x11 <- as.matrix(cbind(1,x1))
  xx <- as.matrix(cbind(x11,x2))
  x <- as.matrix(cbind(x11,x22))
  h1 <- x1%*%solve(t(x1)%*%x1)%*%t(x1)
  h12 <- x22%*%solve(t(x22)%*%(diag(size)-h1)%*%x22)%*%t(x22)%*%(diag(size)-h1)
  reduce <- diag(size)-h12
  batchind <- rep(1:batch,times=sample)
  mod <- model.matrix(~x1)
  mod0 <- model.matrix(~1,data=data.frame(x))
  varbatch <- t(vinvrgamma(gene,shape=alpha,rate=beta))[rep(1:batch,times=sample),]
  resid <- vrnorm(size,mean = 0, sd = res)
  meanbatch <- t(vrnorm(gene,mean,var^0.5))
  null <- mat.or.vec(batch,gene)
  y0 <- t(x%*%rbind(intercept,eff,null)+resid)
  y <- t(x%*%rbind(intercept,eff,meanbatch)+resid*varbatch)
  output[,1] <- eff
  output[,2] <- f.pvalue(y,mod,mod0) ## Raw Data T-Test
  mod1 <- model.matrix(~xx-1)
  mod10 <- model.matrix(~xx[,-2]-1)
  output[,3] <- f.pvalue(y,mod1,mod10) ## One step approach
  output[,4] <- f.pvalue(y0,mod,mod0) ## Benchmark approach, no batch effect
  eb <- ComBat(y,batch = batchind,mod = mod) ## Power would be reduced if choose a reference batch
  output[,5] <- f.pvalue(eb,mod,mod0) ## ComBat without adjustment
  ## Try the correlation matrix formed by reduce 
  ## Choose delta as 10%
  m=reduce%*%t(reduce)
  v=eigen(m)$vectors
  d=eigen(m)$'values'
  noise=sum(d)*0.1
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,6] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 5%
  d=eigen(m)$'values'
  noise=sum(d)*0.05
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,7] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 2%
  d=eigen(m)$'values'
  noise=sum(d)*0.02
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,8] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 1%
  d=eigen(m)$'values'
  noise=sum(d)*0.01
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,9] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.5%
  d=eigen(m)$'values'
  noise=sum(d)*0.005
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,10] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.1%
  d=eigen(m)$'values'
  noise=sum(d)*0.001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,11] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.01%
  d=eigen(m)$'values'
  noise=sum(d)*0.0001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,12] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.001%
  d=eigen(m)$'values'
  noise=sum(d)*0.00001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,13] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.0001%
  d=eigen(m)$'values'
  noise=sum(d)*0.000001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,14] <- f.pvalue(reb,mod4,mod40)
  ## Choose delta as 0.00001%
  d=eigen(m)$'values'
  noise=sum(d)*0.0000001
  d=ifelse(d<0.0001,noise,d) 
  k=v%*%diag(d)%*%t(v)
  s <- solve(t(chol(k)))
  rex <- s%*%x11
  reb <- t(s%*%t(eb))
  mod4 <- model.matrix(~rex-1)
  mod40 <- model.matrix(~rex[,1]-1)
  output[,15] <- f.pvalue(reb,mod4,mod40)
  colnames(output) <- c('TEff','T','1step','Bench','EB',paste0('EB',c(0.1,0.05,0.02,0.01,0.005,0.001,0.0001,0.00001,0.000001,0.0000001)))
  ## result <- apply(output,2,function(x) length(x[x<0.05])/length(x))
  return(output)
}

simbatch <- compiler::cmpfun(simbatch)
out2 <- simbatch(c(181,399,19),c(77,95,0),intercept = rgamma(24000,0.2,0.00006),mean = c(-0.5,0.25,-0.9),var = c(0.27,0.07,0.69),alpha = c(8,100,1.8),beta = c(4,120,0.4),res = rgamma(24000,0.2,0.0002),eff = c(rep(0,14000),rep(c(-2000,-1000,1000,2000),each=2500)))
## Process the result based on p values
processp <- function(out){
  out <- data.frame(out)
  result <- matrix(unlist(by(out[,-1],out$TEff,function(x) apply(x,2,function(x) length(x[x<0.05])))),nrow = 5,byrow = TRUE)
  ## Report FPR and TPR based on p values
  ## Report FPR
  output <- mat.or.vec(2,14)
  rownames(output) <- c('FPR','TPR')
  colnames(output) <- colnames(out)[-1]
  output[1,] <- apply(result,2,function(x) round(x[3]/14000,digits = 3))
  ## Report TPR
  output[2,] <- apply(result,2,function(x) round(sum(x[-3])/10000,digits = 3))
  return(output)
}
st <- processp(out2)
out2 <- data.frame(out2)
## Histogram lines plot based on simulation
x2=invisible(hist(out2$EB))
y2=invisible(hist(out2$Bench))
z2=invisible(hist(out2$EB0.001))
```

```{r figure 4c}
plot(x2$breaks[-length(x2$breaks)],x2$counts,type='l',ylab='Frequency',xlab='p-value',lwd=2,cex.lab=1.5,cex.axis=1.5,cex.main=1.5,main = '(c) Example 4')
lines(y2$breaks[-length(y2$breaks)],y2$counts,lty=2,lwd=2)
lines(z2$breaks[-length(z2$breaks)],z2$counts,lty=3,lwd=2)
legend('topright',legend = c('Benchmark','ComBat','ComBat+Cor'),lty=c(2,1,3),lwd=c(2,2,2),cex = 1.5,xjust = 0.5,yjust = 0.5)
```

#### Third, create figure 5
```{r figure 5}
## Figure 5
tpr <- st[2,5:14]
delta <-factor(c('10%','5%','2%','1%','0.5%','0.1%','0.01%','0.001%','0.0001%','0.00001%'),levels=c('10%','5%','2%','1%','0.5%','0.1%','0.01%','0.001%','0.0001%','0.00001%'))
dat <- cbind.data.frame(delta,tpr)
library(tidyverse)
ggplot(data=dat,aes(x=delta,y=tpr,group=1))+geom_point()+geom_line()+labs(x=expression(zeta),y='TPR')+theme_grey(base_size = 15)
options(warn = defaultW)
```

    